{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import reduce\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x225a8f1cf08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    N, C, H, W = img.shape\n",
    "    NN, CC, HH, WW = img.strides\n",
    "    out_h = (H - filter_h)//stride + 1\n",
    "    out_w = (W - filter_w)//stride + 1\n",
    "    col = np.lib.stride_tricks.as_strided(img, (N, out_h, out_w, C, filter_h, filter_w), (NN, stride * HH, stride * WW, CC, HH, WW)).astype(float)\n",
    "    return col.reshape(np.multiply.reduceat(col.shape, (0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.37454012 0.95071431 0.73199394]\n",
      "   [0.59865848 0.15601864 0.15599452]\n",
      "   [0.05808361 0.86617615 0.60111501]]\n",
      "\n",
      "  [[0.70807258 0.02058449 0.96990985]\n",
      "   [0.83244264 0.21233911 0.18182497]\n",
      "   [0.18340451 0.30424224 0.52475643]]]\n",
      "\n",
      "\n",
      " [[[0.43194502 0.29122914 0.61185289]\n",
      "   [0.13949386 0.29214465 0.36636184]\n",
      "   [0.45606998 0.78517596 0.19967378]]\n",
      "\n",
      "  [[0.51423444 0.59241457 0.04645041]\n",
      "   [0.60754485 0.17052412 0.06505159]\n",
      "   [0.94888554 0.96563203 0.80839735]]]\n",
      "\n",
      "\n",
      " [[[0.30461377 0.09767211 0.68423303]\n",
      "   [0.44015249 0.12203823 0.49517691]\n",
      "   [0.03438852 0.9093204  0.25877998]]\n",
      "\n",
      "  [[0.66252228 0.31171108 0.52006802]\n",
      "   [0.54671028 0.18485446 0.96958463]\n",
      "   [0.77513282 0.93949894 0.89482735]]]]\n",
      "(12, 8)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.random((3,2,3,3))\n",
    "print(a)\n",
    "print(im2col(a, 2, 2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        self.W = {'val': np.random.standard_normal((in_channel,out_channel)), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(out_channel), 'grad': 0}\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = np.dot(X, self.W['val']) + self.b['val']\n",
    "        self.cache = X\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        X = self.cache\n",
    "        dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "        self.W['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
    "        self.b['grad'] = np.sum(dout, axis=0)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weight_size = (self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        self.stride = stride\n",
    "\n",
    "        self.W = {'val': np.random.standard_normal(self.weight_size), 'grad': 0}\n",
    "        self.b = {'val':  np.random.standard_normal((self.out_channels,1)), 'grad': 0}\n",
    "        \n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        (N,C,H,W) = x.shape\n",
    "        self.input_shape = x.shape\n",
    "        H_out = (H - self.kernel_size) // self.stride + 1\n",
    "        W_out = (W - self.kernel_size) // self.stride + 1\n",
    "        conv_out = np.zeros((N, self.out_channels, H_out, W_out))\n",
    "        self.col_image = []\n",
    "        \n",
    "        weight_cols = self.W['val'].reshape(self.out_channels, -1)\n",
    "        for i in range(N):\n",
    "            img_i = x[i][np.newaxis, :]\n",
    "            x_cols = im2col(img_i, self.kernel_size, self.stride)\n",
    "            conv_out[i] = (np.dot(weight_cols, x_cols.T) + self.b['val']).reshape(self.out_channels, H_out, W_out)\n",
    "            self.col_image.append(x_cols)\n",
    "        self.col_image = np.array(self.col_image)\n",
    "        \n",
    "        return conv_out\n",
    "        \n",
    "    def backward(self, error):\n",
    "        (N,C,_,_) = error.shape\n",
    "        error_col = error.reshape(N,C,-1)\n",
    "        for i in range(N):\n",
    "            self.W['grad'] += np.dot(error_col[i], self.col_image[i]).reshape(self.W['val'].shape)\n",
    "        self.b['grad'] += np.sum(error_col, axis=(0,2)).reshape(self.b['val'].shape)\n",
    "        \n",
    "        error_pad =np.pad(error, ((0,0), (0,0), (self.kernel_size - 1, self.kernel_size - 1),\n",
    "                          (self.kernel_size - 1, self.kernel_size - 1)), 'constant', constant_values=0)\n",
    "        \n",
    "        flip_weights = self.W['val'][:, :, ::-1, ::-1]\n",
    "        flip_weights = flip_weights.swapaxes(0,1) # hard to make sure\n",
    "        col_flip_weights = flip_weights.reshape(self.in_channels, -1)\n",
    "        \n",
    "        col_pad_delta = np.array([im2col(error_pad[i][np.newaxis, :], self.kernel_size, self.stride) for i in range(N)])\n",
    "        next_delta = np.dot(col_pad_delta, col_flip_weights.T)\n",
    "        next_delta = np.reshape(next_delta.transpose(0,2,1), self.input_shape)\n",
    "        \n",
    "        return next_delta\n",
    "\n",
    "def im2col(image, kernel_size, stride):\n",
    "    (N, C, H, W) = image.shape\n",
    "    image_col = []\n",
    "    for i in range(0, H - kernel_size + 1, stride):\n",
    "        for j in range(0, W - kernel_size + 1, stride):\n",
    "            col = image[:, :, i:i+kernel_size, j:j+kernel_size].reshape(-1)\n",
    "            image_col.append(col)\n",
    "    image_col = np.array(image_col)\n",
    "    return image_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, F, stride=1, pad=0):\n",
    "        self.kernel_size = F\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.kernel_size) / self.stride)\n",
    "        out_w = int(1 + (W - self.kernel_size) / self.stride)\n",
    "        \n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        # 转换\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d():\n",
    "    def __init__(self, F, stride):\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X: (N, Cin, H, W): maxpool along 3rd, 4th dim\n",
    "        (N,Cin,H,W) = X.shape\n",
    "        F = self.F\n",
    "        W_ = int(float(W)/F)\n",
    "        H_ = int(float(H)/F)\n",
    "        Y = np.zeros((N,Cin,W_,H_))\n",
    "        M = np.zeros(X.shape) # mask\n",
    "        for n in range(N):\n",
    "            for cin in range(Cin):\n",
    "                for w_ in range(W_):\n",
    "                    for h_ in range(H_):\n",
    "                        Y[n,cin,w_,h_] = np.max(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)])\n",
    "                        i,j = np.unravel_index(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)].argmax(), (F,F))\n",
    "                        M[n,cin,F*w_+i,F*h_+j] = 1\n",
    "        self.cache = M\n",
    "        return Y\n",
    "\n",
    "    def backward(self, dout):\n",
    "        M = self.cache\n",
    "        (N,Cin,H,W) = M.shape\n",
    "        dout = np.array(dout)\n",
    "        #print(\"dout.shape: %s, M.shape: %s\" % (dout.shape, M.shape))\n",
    "        dX = np.zeros(M.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(Cin):\n",
    "                #print(\"(n,c): (%s,%s)\" % (n,c))\n",
    "                dX[n,c,:,:] = dout[n,c,:,:].repeat(2, axis=0).repeat(2, axis=1)\n",
    "        return dX*M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "        self.loss = 0\n",
    "        \n",
    "    def forward(self, prediction):\n",
    "        self.prediction = prediction\n",
    "        exp_prediction = np.zeros(prediction.shape)\n",
    "        self.softmax = np.zeros(prediction.shape)\n",
    "        for n in range(prediction.shape[0]):\n",
    "            prediction[n, :] -= np.max(prediction[n, :]) # 防止上溢出\n",
    "            exp_prediction[n] = np.exp(prediction[n])\n",
    "            self.softmax[n] = exp_prediction[n]/np.sum(exp_prediction[n])\n",
    "    \n",
    "        return self.softmax\n",
    "    \n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLoss():\n",
    "    def __init__(self):\n",
    "        self.loss = 0\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        loss = 0.0\n",
    "        N = pred.shape[0]\n",
    "        for n in range(N):\n",
    "            label = target[n]\n",
    "            if pred[n,label] == 0:\n",
    "                loss += 500\n",
    "            else:\n",
    "                self.loss += -np.log(pred[n,label])\n",
    "        return self.loss / N\n",
    "        \n",
    "    def backward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        nllLoss = NLLLoss()\n",
    "        prob = softmax.forward(Y_pred)\n",
    "        loss = nllLoss.forward(prob, Y_true)\n",
    "        dout = prob.copy()\n",
    "        dout[np.arange(N), Y_true] -= 1\n",
    "        return loss, dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \"\"\"\n",
    "    ReLU activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build ReLU\")\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(\"ReLU: _forward\")\n",
    "        out = np.maximum(0, X)\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #print(\"ReLU: _backward\")\n",
    "        X = self.cache\n",
    "        dX = np.array(dout, copy=True)\n",
    "        dX[X <= 0] = 0\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout():\n",
    "    \"\"\"\n",
    "    Dropout layer\n",
    "    \"\"\"\n",
    "    def __init__(self, p=1):\n",
    "        self.cache = None\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, X):\n",
    "        M = (np.random.rand(*X.shape) < self.p) / self.p\n",
    "        self.cache = X, M\n",
    "        return X*M\n",
    "\n",
    "    def backward(self, dout):\n",
    "        X, M = self.cache\n",
    "        dX = dout*M/self.p\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, params, lr=0.001, reg=0):\n",
    "        self.parameters = params\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param['val'] -= (self.lr*param['grad'] + self.reg*param['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum():\n",
    "    def __init__(self, params, lr=0.001, momentum=0.99, reg=0):\n",
    "        self.l = len(params)\n",
    "        self.parameters = params\n",
    "        self.velocities = []\n",
    "        for param in self.parameters:\n",
    "            self.velocities.append(np.zeros(param['val'].shape))\n",
    "        self.lr = lr\n",
    "        self.rho = momentum\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for i in range(self.l):\n",
    "            self.velocities[i] = self.rho*self.velocities[i] + (1-self.rho)*self.parameters[i]['grad']\n",
    "            self.parameters[i]['val'] -= (self.lr*self.velocities[i] + self.reg*self.parameters[i]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5():\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2d(1, 6, 5)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool2d(2,2)\n",
    "        self.conv2 = Conv2d(6, 16, 5)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.pool2 = MaxPool2d(2,2)\n",
    "        self.FC1 = FC(16*4*4, 120)\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84)\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 10)\n",
    "\n",
    "        self.p2_shape = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1.forward(X)\n",
    "        a1 = self.ReLU1.forward(h1)\n",
    "        p1 = self.pool1.forward(a1)\n",
    "        h2 = self.conv2.forward(p1)\n",
    "        a2 = self.ReLU2.forward(h2)\n",
    "        p2 = self.pool2.forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1.forward(fl)\n",
    "        a3 = self.ReLU3.forward(h3)\n",
    "        h4 = self.FC2.forward(a3)\n",
    "        a5 = self.ReLU4.forward(h4)\n",
    "        h5 = self.FC3.forward(a5)\n",
    "        return h5\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = self.FC3.backward(dout)\n",
    "        dout = self.ReLU4.backward(dout)\n",
    "        dout = self.FC2.backward(dout)\n",
    "        dout = self.ReLU3.backward(dout)\n",
    "        dout = self.FC1.backward(dout)\n",
    "        dout = dout.reshape(self.p2_shape) # reshape\n",
    "        dout = self.pool2.backward(dout)\n",
    "        dout = self.ReLU2.backward(dout)\n",
    "        dout = self.conv2.backward(dout)\n",
    "        dout = self.pool1.backward(dout)\n",
    "        dout = self.ReLU1.backward(dout)\n",
    "        dout = self.conv1.backward(dout)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, Y, batch_size):\n",
    "    N = len(X)\n",
    "    i = random.randint(1, N-batch_size)\n",
    "    return X[i:i+batch_size], Y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load()\n",
    "X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_test -= np.mean(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% iter: 0, loss: 0.0\n",
      "0.4% iter: 100, loss: 8.323408721830445\n",
      "0.8% iter: 200, loss: 3.6541897046322243\n",
      "1.2% iter: 300, loss: 2.31903511399816\n",
      "1.6% iter: 400, loss: 2.5446574501661545\n",
      "2.0% iter: 500, loss: 2.379057621098134\n",
      "2.4% iter: 600, loss: 2.4605546619078833\n",
      "2.8% iter: 700, loss: 2.315140848953497\n",
      "3.2% iter: 800, loss: 2.3466039975119717\n",
      "3.6% iter: 900, loss: 2.458078582148251\n",
      "4.0% iter: 1000, loss: 2.505477361838694\n",
      "4.4% iter: 1100, loss: 2.203213270318592\n",
      "4.8% iter: 1200, loss: 2.2997094987697193\n",
      "5.2% iter: 1300, loss: 2.255211500407813\n",
      "5.6% iter: 1400, loss: 2.314987029490116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7e6e0b1eae75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# forward, loss, backward, step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#     print(Y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-5917cc17edc1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-31e5f57d307a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mh_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                         \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                         \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                         \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munravel_index\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "losses = []\n",
    "optim = SGDMomentum(model.get_params(), lr=0.0001, momentum=0.80, reg=0.00003)\n",
    "criterion = CrossEntropyLoss()\n",
    "ITER = 25000\n",
    "for i in range(ITER):\n",
    "    # get batch, make onehot\n",
    "    X_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "\n",
    "    # forward, loss, backward, step\n",
    "    X_batch = X_batch.reshape((batch_size, 1, 28, 28))\n",
    "    Y_pred = model.forward(X_batch)\n",
    "#     print(Y_pred)\n",
    "    loss, dout = criterion.get(Y_pred, Y_batch)\n",
    "#     print(dout)\n",
    "    model.backward(dout)\n",
    "    optim.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"%s%% iter: %s, loss: %s\" % (100*i/ITER,i, loss))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
